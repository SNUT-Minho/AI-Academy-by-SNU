{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 덧셈노드에서 뒤에서 미분해서 전달되는 값은 *1이 된다\n",
    "- 덧셈노드의 역전파는 1을 곱하기만하고 입력된 값을 그대로 다음 노드로 보낸다\n",
    "- 1.3은 만약 z의 값이 1.3 변하게되면 어떻게 되느냐를 보기위한 예시임\n",
    "- Back할때는 반대쪽 node의 가중치로 곱해서 전달된다\n",
    "- + 계산은 그냥흘려보낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Relu에서 역전파 전달 값은? \n",
    "- x>0 일때는 1 /// 0보다 작을때는 0으로 전달된다.\n",
    "- 14p에서 y= 1/x 이다. (ppt 잘못나옴)\n",
    "- 16p (y의 값, 시그모이드 활성화함수를 거친놈은 y의값의 변화량에 따라 x는 y^2*exp(-x)만큼 변화한다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- (2,) : 열벡터도 되고 행백터도 된다 (비어있는 부분은 1D)\n",
    "- (2,3)*(3,) / (3,)*(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- L/W5 = (L/OUTO1)*(OUtO1/netO1)*(netO1/W5)\n",
    "- 즉 전체 Loss의 값을 w5의 변화량으로 확인\n",
    "- 해당 값만큼 -> w를 갱신시켜준다 w - L/W5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
