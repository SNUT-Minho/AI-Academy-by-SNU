{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glob는 파일 경로 읽는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dict(gram_list):\n",
    "    d = defaultdict(lambda:0)\n",
    "    for gram in gram_list:\n",
    "        d[gram]+=1\n",
    "    return d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_prob_sent(sent, bigram_count, bigram_freq):\n",
    "    source = zip(sent[:-1],sent[1:])\n",
    "    res = 1\n",
    "    for bigram in source:\n",
    "        \n",
    "        ####여기 len(bigram_freq) == bigram_count ? 인가?\n",
    "        ## bigram_count = token 몇개인가?\n",
    "        ## len(bigram_freq) type이 몇개인가?\n",
    "        simple_prob = (bigram_freq[bigram]+1)/(bigram_count + len(bigram_freq))\n",
    "        print(bigram, simple_prob)\n",
    "        res *= simple_prob\n",
    "    return res   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLE_prob_sent(sent, unigram_freq, bigram_freq):\n",
    "    source = zip(sent[:-1],sent[1:])\n",
    "    res = 1\n",
    "    for bigram in source:\n",
    "        MLE_prob = (bigram_freq[bigram] + 1) / (unigram_freq[bigram[0]] + len(unigram_freq))\n",
    "        print(bigram, MLE_prob)\n",
    "        res *= MLE_prob\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corpus = ''\n",
    "for f in glob.glob('./brown/*.txt'):\n",
    "    with open(f, newline='\\n') as fp:\n",
    "        corpus += fp.read()\n",
    "corpus = ''.join('^ ' + s + ' $' for s in sent_tokenize(corpus))  \n",
    "unigrams = [re.sub('[_~\\*]','',word) for word in word_tokenize(corpus) if re.search(r'[\\w\\$\\^]+',word)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = [pair for pair in zip(unigrams[:-1],unigrams[1:]) if pair != ('$','^')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '^ I think I will get the best score in this class $'\n",
    "target = target.split()\n",
    "#target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_freq = freq_dict(unigrams)\n",
    "bigram_freq = freq_dict(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('^', 'I') 0.001321131012916931\n",
      "('I', 'think') 7.928085763692357e-05\n",
      "('think', 'I') 2.079497905230782e-05\n",
      "('I', 'will') 3.639121334153869e-05\n",
      "('will', 'get') 5.8485878584615745e-06\n",
      "('get', 'the') 4.613885977230798e-05\n",
      "('the', 'best') 9.552693502153906e-05\n",
      "('best', 'score') 1.2996861907692388e-06\n",
      "('score', 'in') 2.5993723815384776e-06\n",
      "('in', 'this') 0.0002950287653046172\n",
      "('this', 'class') 3.899058572307717e-06\n",
      "('class', '$') 1.4296548098461626e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1352075879527011e-55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_prob_sent(target, len(bigrams), bigram_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('^', 'I') 0.0185419953850223\n",
      "('I', 'think') 0.0019011999376655757\n",
      "('think', 'I') 0.0005447550304722345\n",
      "('I', 'will') 0.0008726819386005921\n",
      "('will', 'get') 0.00014874557895084786\n",
      "('get', 'the') 0.0012027782483482975\n",
      "('the', 'best') 0.0012151974075788638\n",
      "('best', 'score') 3.40988525736109e-05\n",
      "('score', 'in') 6.852365779285298e-05\n",
      "('in', 'this') 0.005834725613674335\n",
      "('this', 'class') 9.634684865515857e-05\n",
      "('class', '$') 0.0003762291577597264\n",
      "1.800564437344899e-39\n"
     ]
    }
   ],
   "source": [
    "print(MLE_prob_sent(target, unigram_freq, bigram_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import *\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_char_lm(fn, order=4):\n",
    "    data = open(fn, 'r').read()\n",
    "    vocab = sorted(set(data))\n",
    "    \n",
    "    lm = defaultdict(Counter)\n",
    "    \n",
    "    pad = '~'*order\n",
    "    data = pad + data\n",
    "    \n",
    "    for i in range(len(data)-order):\n",
    "        history, char = data[i:i+order], data[i+order]\n",
    "        lm[history][char] += 1\n",
    "    \n",
    "    def normalize(counter):\n",
    "        s = sum(counter.values())\n",
    "        return [(c, cnt/s) for c, cnt in counter.items() ]\n",
    "    \n",
    "    outlem = {history: normalize(chars) for history, chars in lm.items()}\n",
    "    \n",
    "    return outlem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm('shakes/shakespeare_train.txt',order=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 0.06912442396313365),\n",
       " (' ', 0.22119815668202766),\n",
       " (\"'\", 0.018433179723502304),\n",
       " (',', 0.20276497695852536),\n",
       " ('-', 0.059907834101382486),\n",
       " ('.', 0.1336405529953917),\n",
       " ('i', 0.03225806451612903),\n",
       " ('\\n', 0.018433179723502304),\n",
       " (':', 0.018433179723502304),\n",
       " (';', 0.027649769585253458),\n",
       " ('?', 0.03225806451612903),\n",
       " ('s', 0.009216589861751152),\n",
       " ('o', 0.15668202764976957)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['hell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', 0.059625212947189095),\n",
       " ('w', 0.817717206132879),\n",
       " ('u', 0.03747870528109029),\n",
       " (',', 0.027257240204429302),\n",
       " (' ', 0.013628620102214651),\n",
       " ('.', 0.0068143100511073255),\n",
       " ('?', 0.0068143100511073255),\n",
       " (':', 0.005110732538330494),\n",
       " ('n', 0.0017035775127768314),\n",
       " (\"'\", 0.017035775127768313),\n",
       " ('!', 0.0068143100511073255)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['ello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d', 1.0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['worl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_letter(lm, history, order):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4525'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"1234567834525\"\n",
    "t = s[-4:]\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 0.06912442396313365),\n",
       " (' ', 0.22119815668202766),\n",
       " (\"'\", 0.018433179723502304),\n",
       " (',', 0.20276497695852536),\n",
       " ('-', 0.059907834101382486),\n",
       " ('.', 0.1336405529953917),\n",
       " ('i', 0.03225806451612903),\n",
       " ('\\n', 0.018433179723502304),\n",
       " (':', 0.018433179723502304),\n",
       " (';', 0.027649769585253458),\n",
       " ('?', 0.03225806451612903),\n",
       " ('s', 0.009216589861751152),\n",
       " ('o', 0.15668202764976957)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['hell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = '~'*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~~~~'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = lm[history[-4:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', 1.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~~~~'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('F', 1.0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['~~~~']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_letter(lm, history, order):\n",
    "    dist = lm[history[-order:]]\n",
    "    x = random.random()\n",
    "    for c,v in dist:\n",
    "        x -= v\n",
    "        if x<=0: return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lm, order, key=1000):\n",
    "    history = '~'*order\n",
    "    out = []\n",
    "    for i in range(key):\n",
    "        c = generate_letter(lm,history,order)\n",
    "        history = history + c\n",
    "        out.append(c)\n",
    "    return ''.join(out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First Fished.\\n\\nROSALIND:\\nO, I have to to myself doing,\\nI see, that youngests.\\nWhat gaunt, 'tis letter fathers too you most no water the and eterm innocention:\\n'Tis I dare,\\nOnce myself, her but crest sound the like are better\\nHe drunk with more palpable must sups have the sad thou breeding that know, Sir Thou wilt light to a kings of loyal plebeians thout for repent off,\\nPlant, how these born upright getter tongue not thee inter is dangers: thorn,\\nIt cannot naturn the should now me.\\n\\nMARINA:\\nWhat may I end my master\\nTo do justice:\\nStay way stood\\nWho evenge, lord.\\n\\nProvoked, bully dismall stride. Frogmore you will lacks touchio's away, but called by all his spoutside thee to the boughter; the\\nkinsman:\\nNo, I will threat know then'd quality: but out often thing you have false I have.\\n\\nNYM:\\nI am mind a cast\\nAs ever Brook.\\n\\nLord Timon, she is All these parcel onest for to a beneface,\\nTo well supportimelessica\\nIn pray'd in might again that reasons his auburning,\\nAnd, my beard, had,\\nTo seem is\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lm,4,key=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
