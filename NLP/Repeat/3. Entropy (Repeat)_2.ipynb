{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Na&iuml;ve Bayes from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(fn):  \n",
    "    lines = csv.reader(open(fn))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows 768\n"
     ]
    }
   ],
   "source": [
    "fn = 'pima-indians-diabetes.data.csv'\n",
    "dataset = load_csv(fn)\n",
    "print('rows', len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_database(dataset, ratio):\n",
    "    train_size = round(len(dataset)*ratio)\n",
    "    copy = list(dataset)\n",
    "    random.shuffle(copy)\n",
    "    return copy[:train_size], copy[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [[1], [5], [2]] , Test: [[4], [3]]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1],[2],[3],[4],[5]]\n",
    "ratio = 0.67\n",
    "train, test = split_database(dataset,ratio)\n",
    "print(f'Train: {train} , Test: {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Separate the training dataset instances by class value ** so that we can calculate statistics for each class.<br\\>\n",
    "dict: each class value -> list of instances that belong to that class<br\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_class(dataset):\n",
    "    sep = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if(vector[-1] not in sep):\n",
    "            sep[vector[-1]] = []\n",
    "        sep[vector[-1]].append(vector)\n",
    "    return sep    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [[1, 20, 1], [3, 22, 1]], 0: [[2, 21, 0], [4, 22, 0]]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = [[1,20,1],[2,21,0],[3,22,1],[4,22,0]]\n",
    "sep = separate_by_class(dataset)\n",
    "sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Summarize ** <br\\>\n",
    "<mark>zip</mark> groups the values for each attribute across our data instances so that we can compute the mean and standard deviation values for the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    summarize  = [(np.mean(attr), np.std(attr)) for attr in zip(*dataset)]\n",
    "    del summarize[-1]\n",
    "    return summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [[1,20,0], [2,21,1], [3,22,0], [4,22,0]]\n",
    "summary = summarize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute summaries: [(2.5, 1.118033988749895), (21.25, 0.82915619758885)]\n"
     ]
    }
   ],
   "source": [
    "print(f'Attribute summaries: {summary}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Summarize attributes by class **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_class(dataset):\n",
    "    sep = separate_by_class(dataset)\n",
    "    summaries = {}\n",
    "    for class_val, instances in sep.items():\n",
    "        summaries[class_val] = summarize(instances)\n",
    "    return summaries   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [(2.0, 1.0), (21.0, 1.0)], 0: [(3.0, 1.0), (21.5, 0.5)]}\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1,20,1], [2,21,0], [3,22,1], [4,22,0]]\n",
    "summary = summarize_by_class(dataset)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predict\n",
    "Calculate the probability that a given data instance belongs to each class, then select the class with the largest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate Gaussian probability density function **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_prob(x, mean, std):\n",
    "    exp = math.exp((-(math.pow(x-mean,2)))/(2*math.pow(std,2)))\n",
    "    return (1/(math.sqrt(2*math.pi)*std))*exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of belonging to this class: 0.06248965759370005\n"
     ]
    }
   ],
   "source": [
    "x = 71.5\n",
    "mean= 73\n",
    "std = 6.2\n",
    "prob = gaussian_prob(x,mean,std)\n",
    "print(f'Probability of belonging to this class: {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {0:[(1, 0.5), (2, 3.5)], 1:[(20, 5.0), (17, 1.5)]}\n",
    "instance = [1.1, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate class probabilities ** <br\\>\n",
    "Multiply the attribute probabilities for each class to get the class probability of a given data instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prob(summaries, instance):\n",
    "    probs = {}\n",
    "    for class_val, class_summ in summaries.items():\n",
    "        probs[class_val] = 1\n",
    "        for i in range(len(class_summ)):\n",
    "            mean, std = class_summ[i]\n",
    "            probs[class_val] *= gaussian_prob(instance[i], mean, std)\n",
    "    return probs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for each class: {0: 0.006540525583425349, 1: 3.126711940345906e-10}\n"
     ]
    }
   ],
   "source": [
    "probs = class_prob(summaries, instance)\n",
    "print(f'Probabilities for each class: {probs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, instance):\n",
    "    probs = class_prob(summaries, instance)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_val, prob in probs.items():\n",
    "        if best_label is None or prob > best_prob:\n",
    "            best_prob = prob\n",
    "            best_label = class_val\n",
    "    return best_label        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "summaries = {0:[(1, 0.5), (2, 3.5)], 1:[(20, 5.0), (17, 1.5)]}\n",
    "instance = [1.1, 10]\n",
    "result = predict(summaries, instance)\n",
    "print(f'Prediction: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Make predictions for test set ** <br\\>\n",
    "Return a list of predictions for each test instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(summaries, test):\n",
    "    preds = []\n",
    "    for x in range(len(test)):\n",
    "        result = predict(summaries, test[x])\n",
    "        preds.append(result)\n",
    "    return preds       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['A', 'B', 'B']\n"
     ]
    }
   ],
   "source": [
    "summaries = {'A':[(1, 0.5), (2, 3.5)], 'B':[(20, 5.0), (17, 1.5)]}\n",
    "test = [[1.1, 5.0], [19.1, 18.3], [18.0, 2.0]]\n",
    "preds = get_predictions(summaries, test)\n",
    "print(f'Predictions: {preds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test, preds):\n",
    "    cor = 0\n",
    "    for x in range(len(test)):\n",
    "        if test[x][-1] == preds[x]:\n",
    "            cor += 1\n",
    "    return cor / len(test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "test = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]  # Ground truth\n",
    "preds = ['a', 'a', 'a']\n",
    "acc = accuracy(test, preds)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work with real dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
