{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apatrue: lens의 굴절율\n",
    "D거리에 있는 애가 focus가 되고\n",
    "D' 거리에 있는 애는 OUT OF FOCUS\n",
    "\n",
    "한점에서 반사된 빛이 다 BLUR CIRCLE로 모이게된다.\n",
    "focus한 물체보다 가깝거나 멀게 있는 물체는 blur처리가 된다.\n",
    "Depth of Field : 대상 물체가 sharp하게 보이는 지역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22p\n",
    "apature를 control함으로써 depth of field를 contorl 할 수 있다.\n",
    "blur circle이 작다는 것은 덜 흐릿하게 보인다는 것임. (average) - > depth of filed가 넓어진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24p \n",
    "Field of view : 세타 (시야각)\n",
    "26P\n",
    "가까이서 찍으면 찌그러져 보인다. 차가\n",
    "멀리서 찍으면 원래의 dimension처럼 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "31p\n",
    "wavelenght: 빨주노초파남보\n",
    "\n",
    "Vignetting: 끝부분의 빛의 소실"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local descriptor : image feature를 vector화\n",
    "각각의 사진에서 동일한 지점의 feature가 일단 먼저 뽑혀야지 -> matching을 진행 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7p\n",
    "feature를 많이 뽑게되면? : 그러면 너무 많이 뽑혀서 안좋음?\n",
    "너무 강하게 distinctive를 주면- (완전히 같아야지만 matching): 조금만 변해도 (robusi/flexible)이 떨어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11p\n",
    "common 한 feature를 뽑으면 구별불가능하다.\n",
    "unusual한 point를 뽑아라.\n",
    "맨오른쪽 그림이 가장 unusual\n",
    "\n",
    "cornor를 detect하자.\n",
    "\n",
    "gradient picture에서 small region의 gradient를 파악 -> 람다값으로 어디인지 확인할 수 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17p\n",
    "기존에는 모든 pixel에 대해서 eigenvalues를 구해야한다(람다큰거 작은거 2개 2x2 Matrix)\n",
    "Cornerness function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19p\n",
    "uniform region detect MSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22P\n",
    "scale의 안과 밖이 차이가 가장 클 때 best scale\n",
    "라플라시안 = difference of 가우시안\n",
    "\n",
    "라플라시안 필터값을 바꿔가면서?\n",
    "라플라시안을 sacle 바꿔가지고 적용을 해가지고 max값일 때의 scale일이 best이다.\n",
    "안과 밖의 가우시안 차이가 가장 클때이기 때문에.\n",
    "\n",
    "Dog (가우신안 필터로 시그마를 바꿔서 쫙 만들어놓고 그걸가지고 laplace sclae 체크)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28p\n",
    "ix : x방향 gradient image\n",
    "iy : y 방향\n",
    "해당 그림의 fetch에대해 ix, iy를 구하고 -> arctan를 사용해서 edge의 angle를 구한다.\n",
    "각각의 pixel별로 0~360도 까지의 angle의 historgram을 쌓아서 구한다.?-\n",
    "- max값을 가지는 historgram의 영역이 0도 방향이 되도록 돌린다.\n",
    "\n",
    "keypoit detectors 마다 trad-off가 있다?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
